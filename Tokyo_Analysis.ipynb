{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a1649fbfa3c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m                  \u001b[1;32mas\u001b[0m     \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m                   \u001b[1;32mas\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotly\u001b[0m           \u001b[1;32mas\u001b[0m     \u001b[0mpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_objs\u001b[0m       \u001b[1;32mas\u001b[0m     \u001b[0mgo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "\n",
    "from   sklearn.linear_model    import LinearRegression\n",
    "from   sklearn.metrics         import mean_squared_error, r2_score\n",
    "import scipy.stats             as     stats\n",
    "import statsmodels.api         as     sm\n",
    "import pandas                  as     pd\n",
    "import numpy                   as     np\n",
    "import plotly\n",
    "import plotly.plotly           as     py\n",
    "import plotly.graph_objs       as     go\n",
    "import seaborn                 as     sns\n",
    "import matplotlib.pyplot       as     plt\n",
    "from   config                  import plotly_id, plotly_key\n",
    "import warnings\n",
    "\n",
    "plotly.tools.set_credentials_file(username=plotly_id, api_key=plotly_key)\n",
    "sns.set(color_codes=True)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "medals = pd.read_csv('Olympic_final_data_191111d.csv')\n",
    "print(medals.shape)\n",
    "medals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy variables\n",
    "model        = pd.get_dummies(data=medals, columns=['NOC','Team','Year','Sport'])\n",
    "model['NOC'] = medals['NOC']\n",
    "model['Team'] = medals['Team']\n",
    "model['Year'] = medals['Year']\n",
    "model['Sport'] = medals['Sport']\n",
    "print(model.shape)\n",
    "model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model[model['Year'] >= 2000]\n",
    "model = model.reset_index().drop(['index'], axis=1)\n",
    "print(model.shape)\n",
    "model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model[['Golds','Silvers','Bronzes']]\n",
    "print(y.shape)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model[['NOC','Team','Year','Sport']]\n",
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[X['Year'] <  2016]\n",
    "X_test  = X[X['Year'] == 2016]\n",
    "X_test  = X_test.reset_index().drop(['index'], axis=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "y_train = y[y['Year'] <  2016]\n",
    "y_test  = y[y['Year'] == 2016]\n",
    "y_test  = y_test.reset_index().drop(['index'], axis=1)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create linear regression objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "regr_golds   = LinearRegression()\n",
    "regr_silvers = LinearRegression()\n",
    "regr_bronzes = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the models using the training sets\n",
    "regr_golds.fit(X_train), (y_train['Golds])\n",
    "regr_silvers.fit(X_train), (y_train['Silvers'])\n",
    "regr_bronzes.fit(X_train), (y_train['Bronzes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the training sets\n",
    "y_train['Golds Prediction']   = pd.DataFrame(\n",
    "    regr_golds.predict(X_train.drop(['Year','NOC','Team'], axis=1)), columns=['Golds Prediction'])\n",
    "y_train['Golds Prediction']   = y_train['Golds Prediction'].astype('int64')\n",
    "y_train['Golds Prediction']   = y_train['Golds Prediction'].clip(lower=0)\n",
    "\n",
    "y_train['Silvers Prediction'] = pd.DataFrame(\n",
    "    regr_silvers.predict(X_train.drop(['Year','NOC','Team'], axis=1)), columns=['Silvers Prediction'])\n",
    "y_train['Silvers Prediction'] = y_train['Silvers Prediction'].astype('int64')\n",
    "y_train['Silvers Prediction'] = y_train['Silvers Prediction'].clip(lower=0)\n",
    "\n",
    "y_train['Bronzes Prediction'] = pd.DataFrame(\n",
    "    regr_bronzes.predict(X_train.drop(['Year','NOC','Team'], axis=1)), columns=['Bronzes Prediction'])\n",
    "y_train['Bronzes Prediction'] = y_train['Bronzes Prediction'].astype('int64')\n",
    "y_train['Bronzes Prediction'] = y_train['Bronzes Prediction'].clip(lower=0)\n",
    "\n",
    "y_train['Medals Prediction']  = y_train['Golds Prediction'] + y_train['Silvers Prediction'] + y_train['Bronzes Prediction']\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intercepts\n",
    "print(regr_golds.intercept_)\n",
    "print(regr_silvers.intercept_)\n",
    "print(regr_bronzes.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coefficients\n",
    "columns                          = X_train.columns.drop(['Year','NOC','Team'])\n",
    "features                         = pd.DataFrame(columns.T, columns=['Feature'])\n",
    "features['Golds Coefficients']   = regr_golds.coef_.T\n",
    "features['Silvers Coefficients'] = regr_silvers.coef_.T\n",
    "features['Bronzes Coefficients'] = regr_bronzes.coef_.T\n",
    "\n",
    "features = features.sort_values(by='Golds Coefficients', ascending=False).reset_index().drop(['index'],axis=1)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "X_test.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the test set\n",
    "y_test['Golds Prediction']   = pd.DataFrame(\n",
    "    regr_golds.predict(X_test.drop(['Year','NOC','Team'], axis=1)), columns=['Golds Prediction'])\n",
    "y_test['Golds Prediction']   = y_test['Golds Prediction'].astype('int64')\n",
    "y_test['Golds Prediction']   = y_test['Golds Prediction'].clip(lower=0)\n",
    "\n",
    "y_test['Silvers Prediction'] = pd.DataFrame(\n",
    "    regr_silvers.predict(X_test.drop(['Year','NOC','Team'], axis=1)), columns=['Silvers Prediction'])\n",
    "y_test['Silvers Prediction'] = y_test['Silvers Prediction'].astype('int64')\n",
    "y_test['Silvers Prediction'] = y_test['Silvers Prediction'].clip(lower=0)\n",
    "\n",
    "y_test['Bronzes Prediction'] = pd.DataFrame(\n",
    "    regr_bronzes.predict(X_test.drop(['Year','NOC','Team'], axis=1)), columns=['Bronzes Prediction'])\n",
    "y_test['Bronzes Prediction'] = y_test['Bronzes Prediction'].astype('int64')\n",
    "y_test['Bronzes Prediction'] = y_test['Bronzes Prediction'].clip(lower=0)\n",
    "\n",
    "y_test['Medals Prediction']  = y_test['Golds Prediction'] + y_test['Silvers Prediction'] + y_test['Bronzes Prediction']\n",
    "y_test.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
